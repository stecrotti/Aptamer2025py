{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16ebae1-958e-47e1-876f-195709423edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T13:25:22.340346Z",
     "iopub.status.busy": "2026-01-22T13:25:22.340064Z",
     "iopub.status.idle": "2026-01-22T13:25:23.495544Z",
     "shell.execute_reply": "2026-01-22T13:25:23.494999Z",
     "shell.execute_reply.started": "2026-01-22T13:25:22.340328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scrotti/Aptamer2025py/selex_dca.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import utils, selex_dca, indep_sites\n",
    "import adabmDCA\n",
    "import selex_distribution, energy_models, tree, data_loading, training, callback, sampling\n",
    "\n",
    "import torch\n",
    "from utils import one_hot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0388f7b2-0087-466e-94ca-5d3b09473b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T13:25:23.496122Z",
     "iopub.status.busy": "2026-01-22T13:25:23.495966Z",
     "iopub.status.idle": "2026-01-22T13:25:23.502079Z",
     "shell.execute_reply": "2026-01-22T13:25:23.501755Z",
     "shell.execute_reply.started": "2026-01-22T13:25:23.496113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training' from '/home/scrotti/Aptamer2025py/training.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(selex_distribution)\n",
    "importlib.reload(energy_models)\n",
    "importlib.reload(sampling)\n",
    "importlib.reload(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd680822-547e-4c76-b9b7-b3d647323390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T13:25:26.492238Z",
     "iopub.status.busy": "2026-01-22T13:25:26.492009Z",
     "iopub.status.idle": "2026-01-22T13:25:26.494986Z",
     "shell.execute_reply": "2026-01-22T13:25:26.494456Z",
     "shell.execute_reply.started": "2026-01-22T13:25:26.492223Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = \"Dop8V030\"\n",
    "round_ids = [\"ARN\", \"R01\", \"R02N\"]\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa56da6-992d-4855-ad43-12a0b542e894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T13:25:27.768504Z",
     "iopub.status.busy": "2026-01-22T13:25:27.768273Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = [utils.sequences_from_file(experiment_id, round_id, device) for round_id in round_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d032172e-500d-4053-b3c5-6a975e1f467a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T12:02:49.552398Z",
     "iopub.status.busy": "2026-01-23T12:02:49.552174Z",
     "iopub.status.idle": "2026-01-23T12:02:49.598322Z",
     "shell.execute_reply": "2026-01-23T12:02:49.597628Z",
     "shell.execute_reply.started": "2026-01-23T12:02:49.552384Z"
    }
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.55 GiB. GPU 0 has a total capacity of 94.97 GiB of which 4.89 GiB is free. Process 2424025 has 84.06 GiB memory in use. Including non-PyTorch memory, this process has 6.01 GiB memory in use. Of the allocated memory 5.39 GiB is allocated by PyTorch, and 1.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sequences_oh = [\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m.to(dtype=dtype, device=device) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Aptamer2025py/utils.py:53\u001b[39m, in \u001b[36mone_hot\u001b[39m\u001b[34m(x, num_classes, dtype)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_hot\u001b[39m(x: torch.Tensor, num_classes: \u001b[38;5;28mint\u001b[39m = -\u001b[32m1\u001b[39m, dtype: torch.dtype = torch.float32) -> torch.Tensor:\n\u001b[32m     42\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A fast one-hot encoding function faster than the PyTorch one working with torch.int32 and returning a float Tensor.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m    Works for both 1D (single sequence) and 2D (batch of sequences) tensors.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m        torch.Tensor: One-hot encoded tensor. Shape (L, num_classes) for 1D input or (batch_size, L, num_classes) for 2D input.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_one_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Aptamer2025py/utils.py:28\u001b[39m, in \u001b[36m_one_hot\u001b[39m\u001b[34m(x, num_classes, dtype)\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Handle 2D case (batch of sequences)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m res = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m tmp = torch.meshgrid(\n\u001b[32m     30\u001b[39m     torch.arange(x.shape[\u001b[32m0\u001b[39m], device=x.device),\n\u001b[32m     31\u001b[39m     torch.arange(x.shape[\u001b[32m1\u001b[39m], device=x.device),\n\u001b[32m     32\u001b[39m     indexing=\u001b[33m\"\u001b[39m\u001b[33mij\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m index = (tmp[\u001b[32m0\u001b[39m], tmp[\u001b[32m1\u001b[39m], x)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 6.55 GiB. GPU 0 has a total capacity of 94.97 GiB of which 4.89 GiB is free. Process 2424025 has 84.06 GiB memory in use. Including non-PyTorch memory, this process has 6.01 GiB memory in use. Of the allocated memory 5.39 GiB is allocated by PyTorch, and 1.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "sequences_oh = [one_hot(seq).to(dtype=dtype, device=device) for seq in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3060a-8efe-483b-a291-8bb60a2e0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reads = torch.Tensor([s.shape[0] for s in sequences_oh]).to(device)\n",
    "fi0, _, _ = utils.frequences_from_sequences_oh(sequences_oh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e558b76-f19d-4bf5-9937-b031c4f6c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, q = sequences_oh[0][0].shape\n",
    "k = torch.zeros(L, q, dtype=dtype, device=device)\n",
    "h = torch.zeros(L, q, dtype=dtype, device=device)\n",
    "J = torch.zeros(L, q, L, q, dtype=dtype, device=device)\n",
    "\n",
    "tr = tree.Tree()\n",
    "tr.add_node(-1)\n",
    "tr.add_node(0)\n",
    "\n",
    "selected_modes = torch.BoolTensor([[1],[1]]).to(device)\n",
    "\n",
    "Ns0 = energy_models.IndepSites(k)\n",
    "potts = energy_models.Potts(J, h)\n",
    "indep = energy_models.IndepSites(h)\n",
    "ps = selex_distribution.MultiModeDistribution(potts, normalized=False)\n",
    "model = selex_distribution.MultiRoundDistribution(Ns0, ps, tr, selected_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51080269-670c-477d-a2c6-f1980e104886",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10**6\n",
    "data_loaders = [data_loading.SelexRoundDataLoader(seq_oh, batch_size=batch_size) for seq_oh in sequences_oh]\n",
    "n_rounds = len(data_loaders) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d768b07-a3c8-494e-8ac9-37c7e4403911",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 10**4\n",
    "\n",
    "chains = training.init_chains(n_rounds, n_chains, L, q, device, dtype)\n",
    "log_weights = torch.zeros(n_rounds, n_chains, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7163754-c0c9-45a2-89a2-619e20bbcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback.ConvergenceMetricsCallback(), callback.PearsonCovarianceCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba6d2d-f4f2-4bf5-a4db-0ae29dc5d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed35981-b7a4-4a9e-b01c-9c2e25a1d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sweeps = 10\n",
    "lr = 0.01\n",
    "target_pearson = 1\n",
    "max_epochs = 50\n",
    "\n",
    "%lprun -f training.train training.train(model, data_loaders, total_reads, chains, n_sweeps, lr, max_epochs, target_pearson, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b10dfe-628d-4643-94ba-6d0a84e3f657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T22:48:17.668906Z",
     "iopub.status.busy": "2026-01-22T22:48:17.668379Z",
     "iopub.status.idle": "2026-01-22T22:48:17.686460Z",
     "shell.execute_reply": "2026-01-22T22:48:17.685763Z",
     "shell.execute_reply.started": "2026-01-22T22:48:17.668829Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'callbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcallbacks\u001b[49m[\u001b[32m0\u001b[39m].plot();\n",
      "\u001b[31mNameError\u001b[39m: name 'callbacks' is not defined"
     ]
    }
   ],
   "source": [
    "callbacks[0].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527d25e-afac-4bf3-a284-7d97f3bf2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = callbacks[1].plot()\n",
    "ax.axhline(1, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763b002-2d1a-4412-a8aa-36a0dc0f0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Latex\n",
    "\n",
    "potts_zerosum = potts.set_zerosum_gauge()\n",
    "\n",
    "pl, ax = plt.subplots(figsize=(3,3))\n",
    "F = selex_dca.get_contact_map(potts_zerosum.J.detach())\n",
    "im = ax.imshow(F)\n",
    "ax.set_xlabel(\"i\"); ax.set_ylabel(\"i\")\n",
    "ax.set_title(experiment_id)\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "# im.set_clim(-0.0015, 0.0030)\n",
    "display(Latex(\"$F_{ij}=\\\\sqrt {\\\\sum_{ab}(J_{ij}^{ab})^2}$\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
